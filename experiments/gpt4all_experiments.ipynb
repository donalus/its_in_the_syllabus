{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gpt4all import GPT4All, gpt4all\n",
    "import langchain\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"orca-mini-3b-gguf2-q4_0.gguf\"\n",
    "#model_name = \"Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf\"\n",
    "#model_name = \"Meta-Llama-3-8B-Instruct.Q4_0.gguf\"\n",
    "model_name = \"mistral-7b-openorca.gguf2.Q4_0.gguf\"\n",
    "model_path = Path('..') / \"models\"\n",
    "\n",
    "model = GPT4All(model_name=model_name, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,0\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\"The capital of France is \", max_tokens=3)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '<|im_start|>system\\nYou are MistralOrca, a large language model trained by Alignment Lab AI.\\n<|im_end|>\\n'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ' Hello! How can I help you today?'}, {'role': 'user', 'content': 'write me a short poem'}, {'role': 'assistant', 'content': \" The sun sets in hues of gold and red,\\nA gentle breeze rustles through the trees,\\nThe world is calm, and all is said,\\nExcept for whispers from the seas.\\n\\nIn this moment, time stands still,\\nAs nature's beauty fills our hearts with thrill;\\nWe pause to take in every detail,\\nAnd let life's rhythm fill us with zeal.\"}, {'role': 'user', 'content': 'thank you'}, {'role': 'assistant', 'content': ' You are most welcome! If there is anything else I can help you with or if you have any other requests, feel free to ask.'}]\n"
     ]
    }
   ],
   "source": [
    "with model.chat_session():\n",
    "    response1 = model.generate(prompt='hello', temp=0)\n",
    "    response2 = model.generate(prompt='write me a short poem', temp=0)\n",
    "    response3 = model.generate(prompt='thank you', temp=0)\n",
    "    print(model.current_chat_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '<|im_start|>system\\nYou are MistralOrca, a large language model trained by Alignment Lab AI.\\n<|im_end|>\\n'}, {'role': 'user', 'content': 'What is the capital of France?'}, {'role': 'assistant', 'content': ' The capital of France is Paris.'}]\n",
      "[' The', ' capital', ' of', ' France', ' is', ' Paris', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "with model.chat_session():\n",
    "    for token in model.generate(\"What is the capital of France?\", streaming=True):\n",
    "        tokens.append(token)\n",
    "    print(model.current_chat_session)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The grass appears green because of the way our eyes perceive light. Chlorophyll, a pigment found in plants like grass, reflects green light very efficiently while absorbing other colors. This causes us to see the plant as green when it's hit by sunlight containing all the colors of the rainbow.\n",
      "\n",
      " The sky appears blue due to a phenomenon called Rayleigh scattering, which occurs when tiny particles in Earth's atmosphere (like air molecules and dust) scatter light from the sun. Blue light gets scattered more efficiently than other colors, so we perceive the sky as blue.\n"
     ]
    }
   ],
   "source": [
    "system_template = 'A chat between a curious user and an artificial intelligence assistant.\\n'\n",
    "# many models use triple hash '###' for keywords, Vicunas are simpler:\n",
    "prompt_template = 'USER: {0}\\nASSISTANT: '\n",
    "with model.chat_session(system_template, prompt_template):\n",
    "    response1 = model.generate('why is the grass green?')\n",
    "    print(response1)\n",
    "    print()\n",
    "    response2 = model.generate('why is the sky blue?')\n",
    "    print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23 entries, 0 to 22\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   order           23 non-null     object\n",
      " 1   md5sum          23 non-null     object\n",
      " 2   name            23 non-null     object\n",
      " 3   filename        23 non-null     object\n",
      " 4   filesize        23 non-null     object\n",
      " 5   requires        23 non-null     object\n",
      " 6   ramrequired     23 non-null     object\n",
      " 7   parameters      23 non-null     object\n",
      " 8   quant           23 non-null     object\n",
      " 9   type            23 non-null     object\n",
      " 10  description     23 non-null     object\n",
      " 11  url             23 non-null     object\n",
      " 12  promptTemplate  15 non-null     object\n",
      " 13  systemPrompt    22 non-null     object\n",
      " 14  removedIn       2 non-null      object\n",
      " 15  disableGUI      6 non-null      object\n",
      " 16  embeddingModel  4 non-null      object\n",
      "dtypes: object(17)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "models_df = pd.DataFrame(model.list_models())\n",
    "models_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>md5sum</th>\n",
       "      <th>name</th>\n",
       "      <th>filename</th>\n",
       "      <th>filesize</th>\n",
       "      <th>requires</th>\n",
       "      <th>ramrequired</th>\n",
       "      <th>parameters</th>\n",
       "      <th>quant</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>promptTemplate</th>\n",
       "      <th>systemPrompt</th>\n",
       "      <th>removedIn</th>\n",
       "      <th>disableGUI</th>\n",
       "      <th>embeddingModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>c87ad09e1e4c8f9c35a5fcef52b6f1c9</td>\n",
       "      <td>Llama 3 Instruct</td>\n",
       "      <td>Meta-Llama-3-8B-Instruct.Q4_0.gguf</td>\n",
       "      <td>4661724384</td>\n",
       "      <td>2.7.1</td>\n",
       "      <td>8</td>\n",
       "      <td>8 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>LLaMA3</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Fast responses&lt;/li&gt;&lt;li&gt;Chat based mode...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/Meta-Llama-3-8B...</td>\n",
       "      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n%1...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>a5f6b4eabd3992da4d7fb7f020f921eb</td>\n",
       "      <td>Nous Hermes 2 Mistral DPO</td>\n",
       "      <td>Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf</td>\n",
       "      <td>4108928000</td>\n",
       "      <td>2.7.1</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>&lt;strong&gt;Best overall fast chat model&lt;/strong&gt;&lt;...</td>\n",
       "      <td>https://huggingface.co/NousResearch/Nous-Herme...</td>\n",
       "      <td>&lt;|im_start|&gt;user\\n%1&lt;|im_end|&gt;\\n&lt;|im_start|&gt;as...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>97463be739b50525df56d33b26b00852</td>\n",
       "      <td>Mistral Instruct</td>\n",
       "      <td>mistral-7b-instruct-v0.1.Q4_0.gguf</td>\n",
       "      <td>4108916384</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>&lt;strong&gt;Strong overall fast instruction follow...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/mistral-7b-inst...</td>\n",
       "      <td>[INST] %1 [/INST]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>f692417a22405d80573ac10cb0cd6c6a</td>\n",
       "      <td>Mistral OpenOrca</td>\n",
       "      <td>mistral-7b-openorca.gguf2.Q4_0.gguf</td>\n",
       "      <td>4108928128</td>\n",
       "      <td>2.7.1</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>&lt;strong&gt;Strong overall fast chat model&lt;/strong...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/mistral-7b-open...</td>\n",
       "      <td>&lt;|im_start|&gt;user\\n%1&lt;|im_end|&gt;\\n&lt;|im_start|&gt;as...</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are MistralOrca, a lar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>c4c78adf744d6a20f05c8751e3961b84</td>\n",
       "      <td>GPT4All Falcon</td>\n",
       "      <td>gpt4all-falcon-newbpe-q4_0.gguf</td>\n",
       "      <td>4210994112</td>\n",
       "      <td>2.6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>Falcon</td>\n",
       "      <td>&lt;strong&gt;Very fast model with good quality&lt;/str...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/gpt4all-falcon-...</td>\n",
       "      <td>### Instruction:\\n%1\\n\\n### Response:\\n</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>00c8593ba57f5240f59662367b3ed4a5</td>\n",
       "      <td>Orca 2 (Medium)</td>\n",
       "      <td>orca-2-7b.Q4_0.gguf</td>\n",
       "      <td>3825824192</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>LLaMA2</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Instruction based&lt;li&gt;Trained by Micros...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/orca-2-7b.Q4_0....</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>3c0d63c4689b9af7baa82469a6f51a19</td>\n",
       "      <td>Orca 2 (Full)</td>\n",
       "      <td>orca-2-13b.Q4_0.gguf</td>\n",
       "      <td>7365856064</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>16</td>\n",
       "      <td>13 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>LLaMA2</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Instruction based&lt;li&gt;Trained by Micros...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/orca-2-13b.Q4_0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>5aff90007499bce5c64b1c0760c0b186</td>\n",
       "      <td>Wizard v1.2</td>\n",
       "      <td>wizardlm-13b-v1.2.Q4_0.gguf</td>\n",
       "      <td>7365834624</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>16</td>\n",
       "      <td>13 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>LLaMA2</td>\n",
       "      <td>&lt;strong&gt;Strong overall larger model&lt;/strong&gt;&lt;b...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/wizardlm-13b-v1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>31b47b4e8c1816b62684ac3ca373f9e1</td>\n",
       "      <td>Ghost 7B v0.9.1</td>\n",
       "      <td>ghost-7b-v0.9.1-Q4_0.gguf</td>\n",
       "      <td>4108916960</td>\n",
       "      <td>2.7.1</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>&lt;strong&gt;Ghost 7B v0.9.1&lt;/strong&gt; fast, powerfu...</td>\n",
       "      <td>https://huggingface.co/lamhieu/ghost-7b-v0.9.1...</td>\n",
       "      <td>&lt;|user|&gt;\\n%1&lt;/s&gt;\\n&lt;|assistant|&gt;\\n%2&lt;/s&gt;\\n</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are Ghost created by Lam Hieu....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>j</td>\n",
       "      <td>3d12810391d04d1153b692626c0c6e16</td>\n",
       "      <td>Hermes</td>\n",
       "      <td>nous-hermes-llama2-13b.Q4_0.gguf</td>\n",
       "      <td>7366062080</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>16</td>\n",
       "      <td>13 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>LLaMA2</td>\n",
       "      <td>&lt;strong&gt;Extremely good model&lt;/strong&gt;&lt;br&gt;&lt;ul&gt;&lt;...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/nous-hermes-lla...</td>\n",
       "      <td>### Instruction:\\n%1\\n\\n### Response:\\n</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k</td>\n",
       "      <td>40388eb2f8d16bb5d08c96fdfaac6b2c</td>\n",
       "      <td>Snoozy</td>\n",
       "      <td>gpt4all-13b-snoozy-q4_0.gguf</td>\n",
       "      <td>7365834624</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>16</td>\n",
       "      <td>13 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>LLaMA</td>\n",
       "      <td>&lt;strong&gt;Very good overall model&lt;/strong&gt;&lt;br&gt;&lt;u...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/gpt4all-13b-sno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l</td>\n",
       "      <td>15dcb4d7ea6de322756449c11a0b7545</td>\n",
       "      <td>MPT Chat</td>\n",
       "      <td>mpt-7b-chat-newbpe-q4_0.gguf</td>\n",
       "      <td>3912373472</td>\n",
       "      <td>2.7.1</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>MPT</td>\n",
       "      <td>&lt;strong&gt;Good model with novel architecture&lt;/st...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/mpt-7b-chat-new...</td>\n",
       "      <td>&lt;|im_start|&gt;user\\n%1&lt;|im_end|&gt;\\n&lt;|im_start|&gt;as...</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n- You are a helpful assist...</td>\n",
       "      <td>2.7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>l</td>\n",
       "      <td>ab5d8e8a2f79365ea803c1f1d0aa749d</td>\n",
       "      <td>MPT Chat</td>\n",
       "      <td>mpt-7b-chat.gguf4.Q4_0.gguf</td>\n",
       "      <td>3796178112</td>\n",
       "      <td>2.7.3</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>MPT</td>\n",
       "      <td>&lt;strong&gt;Good model with novel architecture&lt;/st...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/mpt-7b-chat.ggu...</td>\n",
       "      <td>&lt;|im_start|&gt;user\\n%1&lt;|im_end|&gt;\\n&lt;|im_start|&gt;as...</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n- You are a helpful assist...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>m</td>\n",
       "      <td>f8347badde9bfc2efbe89124d78ddaf5</td>\n",
       "      <td>Phi-3 Mini Instruct</td>\n",
       "      <td>Phi-3-mini-4k-instruct.Q4_0.gguf</td>\n",
       "      <td>2176181568</td>\n",
       "      <td>2.7.1</td>\n",
       "      <td>4</td>\n",
       "      <td>4 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>Phi-3</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Very fast responses&lt;/li&gt;&lt;li&gt;Chat based...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/Phi-3-mini-4k-i...</td>\n",
       "      <td>&lt;|user|&gt;\\n%1&lt;|end|&gt;\\n&lt;|assistant|&gt;\\n%2&lt;|end|&gt;\\n</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n</td>\n",
       "      <td>0e769317b90ac30d6e09486d61fefa26</td>\n",
       "      <td>Mini Orca (Small)</td>\n",
       "      <td>orca-mini-3b-gguf2-q4_0.gguf</td>\n",
       "      <td>1979946720</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>OpenLLaMa</td>\n",
       "      <td>&lt;strong&gt;Small version of new model with novel ...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/orca-mini-3b-gg...</td>\n",
       "      <td>### User:\\n%1\\n\\n### Response:\\n</td>\n",
       "      <td>### System:\\nYou are an AI assistant that foll...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>o</td>\n",
       "      <td>c232f17e09bca4b7ee0b5b1f4107c01e</td>\n",
       "      <td>Replit</td>\n",
       "      <td>replit-code-v1_5-3b-newbpe-q4_0.gguf</td>\n",
       "      <td>1953055104</td>\n",
       "      <td>2.6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>Replit</td>\n",
       "      <td>&lt;strong&gt;Trained on subset of the Stack&lt;/strong...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/replit-code-v1_...</td>\n",
       "      <td>%1</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>true</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>p</td>\n",
       "      <td>70841751ccd95526d3dcfa829e11cd4c</td>\n",
       "      <td>Starcoder</td>\n",
       "      <td>starcoder-newbpe-q4_0.gguf</td>\n",
       "      <td>8987411904</td>\n",
       "      <td>2.6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>Starcoder</td>\n",
       "      <td>&lt;strong&gt;Trained on subset of the Stack&lt;/strong...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/starcoder-newbp...</td>\n",
       "      <td>%1</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>true</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>q</td>\n",
       "      <td>e973dd26f0ffa6e46783feaea8f08c83</td>\n",
       "      <td>Rift coder</td>\n",
       "      <td>rift-coder-v0-7b-q4_0.gguf</td>\n",
       "      <td>3825903776</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>LLaMA</td>\n",
       "      <td>&lt;strong&gt;Trained on collection of Python and Ty...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/rift-coder-v0-7...</td>\n",
       "      <td>%1</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>true</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>r</td>\n",
       "      <td>e479e6f38b59afc51a470d1953a6bfc7</td>\n",
       "      <td>SBert</td>\n",
       "      <td>all-MiniLM-L6-v2-f16.gguf</td>\n",
       "      <td>45887744</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40 million</td>\n",
       "      <td>f16</td>\n",
       "      <td>Bert</td>\n",
       "      <td>&lt;strong&gt;LocalDocs text embeddings model&lt;/stron...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/all-MiniLM-L6-v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.7.4</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>r</td>\n",
       "      <td>dd90e2cb7f8e9316ac3796cece9883b5</td>\n",
       "      <td>SBert</td>\n",
       "      <td>all-MiniLM-L6-v2.gguf2.f16.gguf</td>\n",
       "      <td>45949216</td>\n",
       "      <td>2.7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>40 million</td>\n",
       "      <td>f16</td>\n",
       "      <td>Bert</td>\n",
       "      <td>&lt;strong&gt;LocalDocs text embeddings model&lt;/stron...</td>\n",
       "      <td>https://gpt4all.io/models/gguf/all-MiniLM-L6-v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>s</td>\n",
       "      <td>919de4dd6f25351bcb0223790db1932d</td>\n",
       "      <td>EM German Mistral</td>\n",
       "      <td>em_german_mistral_v01.Q4_0.gguf</td>\n",
       "      <td>4108916352</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7 billion</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>&lt;strong&gt;Mistral-based model for German-languag...</td>\n",
       "      <td>https://huggingface.co/TheBloke/em_german_mist...</td>\n",
       "      <td>USER: %1 ASSISTANT:</td>\n",
       "      <td>Du bist ein hilfreicher Assistent.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>t</td>\n",
       "      <td>60ea031126f82db8ddbbfecc668315d2</td>\n",
       "      <td>Nomic Embed Text v1</td>\n",
       "      <td>nomic-embed-text-v1.f16.gguf</td>\n",
       "      <td>274290560</td>\n",
       "      <td>2.7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>137 million</td>\n",
       "      <td>f16</td>\n",
       "      <td>Bert</td>\n",
       "      <td>nomic-embed-text-v1</td>\n",
       "      <td>https://gpt4all.io/models/gguf/nomic-embed-tex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>u</td>\n",
       "      <td>a5401e7f7e46ed9fcaed5b60a281d547</td>\n",
       "      <td>Nomic Embed Text v1.5</td>\n",
       "      <td>nomic-embed-text-v1.5.f16.gguf</td>\n",
       "      <td>274290560</td>\n",
       "      <td>2.7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>137 million</td>\n",
       "      <td>f16</td>\n",
       "      <td>Bert</td>\n",
       "      <td>nomic-embed-text-v1.5</td>\n",
       "      <td>https://gpt4all.io/models/gguf/nomic-embed-tex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order                            md5sum                       name  \\\n",
       "0      a  c87ad09e1e4c8f9c35a5fcef52b6f1c9           Llama 3 Instruct   \n",
       "1      b  a5f6b4eabd3992da4d7fb7f020f921eb  Nous Hermes 2 Mistral DPO   \n",
       "2      c  97463be739b50525df56d33b26b00852           Mistral Instruct   \n",
       "3      d  f692417a22405d80573ac10cb0cd6c6a           Mistral OpenOrca   \n",
       "4      e  c4c78adf744d6a20f05c8751e3961b84             GPT4All Falcon   \n",
       "5      f  00c8593ba57f5240f59662367b3ed4a5            Orca 2 (Medium)   \n",
       "6      g  3c0d63c4689b9af7baa82469a6f51a19              Orca 2 (Full)   \n",
       "7      h  5aff90007499bce5c64b1c0760c0b186                Wizard v1.2   \n",
       "8      i  31b47b4e8c1816b62684ac3ca373f9e1            Ghost 7B v0.9.1   \n",
       "9      j  3d12810391d04d1153b692626c0c6e16                     Hermes   \n",
       "10     k  40388eb2f8d16bb5d08c96fdfaac6b2c                     Snoozy   \n",
       "11     l  15dcb4d7ea6de322756449c11a0b7545                   MPT Chat   \n",
       "12     l  ab5d8e8a2f79365ea803c1f1d0aa749d                   MPT Chat   \n",
       "13     m  f8347badde9bfc2efbe89124d78ddaf5        Phi-3 Mini Instruct   \n",
       "14     n  0e769317b90ac30d6e09486d61fefa26          Mini Orca (Small)   \n",
       "15     o  c232f17e09bca4b7ee0b5b1f4107c01e                     Replit   \n",
       "16     p  70841751ccd95526d3dcfa829e11cd4c                  Starcoder   \n",
       "17     q  e973dd26f0ffa6e46783feaea8f08c83                 Rift coder   \n",
       "18     r  e479e6f38b59afc51a470d1953a6bfc7                      SBert   \n",
       "19     r  dd90e2cb7f8e9316ac3796cece9883b5                      SBert   \n",
       "20     s  919de4dd6f25351bcb0223790db1932d          EM German Mistral   \n",
       "21     t  60ea031126f82db8ddbbfecc668315d2        Nomic Embed Text v1   \n",
       "22     u  a5401e7f7e46ed9fcaed5b60a281d547      Nomic Embed Text v1.5   \n",
       "\n",
       "                                  filename    filesize requires ramrequired  \\\n",
       "0       Meta-Llama-3-8B-Instruct.Q4_0.gguf  4661724384    2.7.1           8   \n",
       "1   Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf  4108928000    2.7.1           8   \n",
       "2       mistral-7b-instruct-v0.1.Q4_0.gguf  4108916384    2.5.0           8   \n",
       "3      mistral-7b-openorca.gguf2.Q4_0.gguf  4108928128    2.7.1           8   \n",
       "4          gpt4all-falcon-newbpe-q4_0.gguf  4210994112    2.6.0           8   \n",
       "5                      orca-2-7b.Q4_0.gguf  3825824192    2.5.2           8   \n",
       "6                     orca-2-13b.Q4_0.gguf  7365856064    2.5.2          16   \n",
       "7              wizardlm-13b-v1.2.Q4_0.gguf  7365834624    2.5.0          16   \n",
       "8                ghost-7b-v0.9.1-Q4_0.gguf  4108916960    2.7.1           8   \n",
       "9         nous-hermes-llama2-13b.Q4_0.gguf  7366062080    2.5.0          16   \n",
       "10            gpt4all-13b-snoozy-q4_0.gguf  7365834624    2.5.0          16   \n",
       "11            mpt-7b-chat-newbpe-q4_0.gguf  3912373472    2.7.1           8   \n",
       "12             mpt-7b-chat.gguf4.Q4_0.gguf  3796178112    2.7.3           8   \n",
       "13        Phi-3-mini-4k-instruct.Q4_0.gguf  2176181568    2.7.1           4   \n",
       "14            orca-mini-3b-gguf2-q4_0.gguf  1979946720    2.5.0           4   \n",
       "15    replit-code-v1_5-3b-newbpe-q4_0.gguf  1953055104    2.6.0           4   \n",
       "16              starcoder-newbpe-q4_0.gguf  8987411904    2.6.0           4   \n",
       "17              rift-coder-v0-7b-q4_0.gguf  3825903776    2.5.0           8   \n",
       "18               all-MiniLM-L6-v2-f16.gguf    45887744    2.5.0           1   \n",
       "19         all-MiniLM-L6-v2.gguf2.f16.gguf    45949216    2.7.4           1   \n",
       "20         em_german_mistral_v01.Q4_0.gguf  4108916352    2.5.0           8   \n",
       "21            nomic-embed-text-v1.f16.gguf   274290560    2.7.4           1   \n",
       "22          nomic-embed-text-v1.5.f16.gguf   274290560    2.7.4           1   \n",
       "\n",
       "     parameters quant       type  \\\n",
       "0     8 billion  q4_0     LLaMA3   \n",
       "1     7 billion  q4_0    Mistral   \n",
       "2     7 billion  q4_0    Mistral   \n",
       "3     7 billion  q4_0    Mistral   \n",
       "4     7 billion  q4_0     Falcon   \n",
       "5     7 billion  q4_0     LLaMA2   \n",
       "6    13 billion  q4_0     LLaMA2   \n",
       "7    13 billion  q4_0     LLaMA2   \n",
       "8     7 billion  q4_0    Mistral   \n",
       "9    13 billion  q4_0     LLaMA2   \n",
       "10   13 billion  q4_0      LLaMA   \n",
       "11    7 billion  q4_0        MPT   \n",
       "12    7 billion  q4_0        MPT   \n",
       "13    4 billion  q4_0      Phi-3   \n",
       "14    3 billion  q4_0  OpenLLaMa   \n",
       "15    3 billion  q4_0     Replit   \n",
       "16    7 billion  q4_0  Starcoder   \n",
       "17    7 billion  q4_0      LLaMA   \n",
       "18   40 million   f16       Bert   \n",
       "19   40 million   f16       Bert   \n",
       "20    7 billion  q4_0    Mistral   \n",
       "21  137 million   f16       Bert   \n",
       "22  137 million   f16       Bert   \n",
       "\n",
       "                                          description  \\\n",
       "0   <ul><li>Fast responses</li><li>Chat based mode...   \n",
       "1   <strong>Best overall fast chat model</strong><...   \n",
       "2   <strong>Strong overall fast instruction follow...   \n",
       "3   <strong>Strong overall fast chat model</strong...   \n",
       "4   <strong>Very fast model with good quality</str...   \n",
       "5   <ul><li>Instruction based<li>Trained by Micros...   \n",
       "6   <ul><li>Instruction based<li>Trained by Micros...   \n",
       "7   <strong>Strong overall larger model</strong><b...   \n",
       "8   <strong>Ghost 7B v0.9.1</strong> fast, powerfu...   \n",
       "9   <strong>Extremely good model</strong><br><ul><...   \n",
       "10  <strong>Very good overall model</strong><br><u...   \n",
       "11  <strong>Good model with novel architecture</st...   \n",
       "12  <strong>Good model with novel architecture</st...   \n",
       "13  <ul><li>Very fast responses</li><li>Chat based...   \n",
       "14  <strong>Small version of new model with novel ...   \n",
       "15  <strong>Trained on subset of the Stack</strong...   \n",
       "16  <strong>Trained on subset of the Stack</strong...   \n",
       "17  <strong>Trained on collection of Python and Ty...   \n",
       "18  <strong>LocalDocs text embeddings model</stron...   \n",
       "19  <strong>LocalDocs text embeddings model</stron...   \n",
       "20  <strong>Mistral-based model for German-languag...   \n",
       "21                                nomic-embed-text-v1   \n",
       "22                              nomic-embed-text-v1.5   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://gpt4all.io/models/gguf/Meta-Llama-3-8B...   \n",
       "1   https://huggingface.co/NousResearch/Nous-Herme...   \n",
       "2   https://gpt4all.io/models/gguf/mistral-7b-inst...   \n",
       "3   https://gpt4all.io/models/gguf/mistral-7b-open...   \n",
       "4   https://gpt4all.io/models/gguf/gpt4all-falcon-...   \n",
       "5   https://gpt4all.io/models/gguf/orca-2-7b.Q4_0....   \n",
       "6   https://gpt4all.io/models/gguf/orca-2-13b.Q4_0...   \n",
       "7   https://gpt4all.io/models/gguf/wizardlm-13b-v1...   \n",
       "8   https://huggingface.co/lamhieu/ghost-7b-v0.9.1...   \n",
       "9   https://gpt4all.io/models/gguf/nous-hermes-lla...   \n",
       "10  https://gpt4all.io/models/gguf/gpt4all-13b-sno...   \n",
       "11  https://gpt4all.io/models/gguf/mpt-7b-chat-new...   \n",
       "12  https://gpt4all.io/models/gguf/mpt-7b-chat.ggu...   \n",
       "13  https://gpt4all.io/models/gguf/Phi-3-mini-4k-i...   \n",
       "14  https://gpt4all.io/models/gguf/orca-mini-3b-gg...   \n",
       "15  https://gpt4all.io/models/gguf/replit-code-v1_...   \n",
       "16  https://gpt4all.io/models/gguf/starcoder-newbp...   \n",
       "17  https://gpt4all.io/models/gguf/rift-coder-v0-7...   \n",
       "18  https://gpt4all.io/models/gguf/all-MiniLM-L6-v...   \n",
       "19  https://gpt4all.io/models/gguf/all-MiniLM-L6-v...   \n",
       "20  https://huggingface.co/TheBloke/em_german_mist...   \n",
       "21  https://gpt4all.io/models/gguf/nomic-embed-tex...   \n",
       "22  https://gpt4all.io/models/gguf/nomic-embed-tex...   \n",
       "\n",
       "                                       promptTemplate  \\\n",
       "0   <|start_header_id|>user<|end_header_id|>\\n\\n%1...   \n",
       "1   <|im_start|>user\\n%1<|im_end|>\\n<|im_start|>as...   \n",
       "2                                   [INST] %1 [/INST]   \n",
       "3   <|im_start|>user\\n%1<|im_end|>\\n<|im_start|>as...   \n",
       "4             ### Instruction:\\n%1\\n\\n### Response:\\n   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8           <|user|>\\n%1</s>\\n<|assistant|>\\n%2</s>\\n   \n",
       "9             ### Instruction:\\n%1\\n\\n### Response:\\n   \n",
       "10                                                NaN   \n",
       "11  <|im_start|>user\\n%1<|im_end|>\\n<|im_start|>as...   \n",
       "12  <|im_start|>user\\n%1<|im_end|>\\n<|im_start|>as...   \n",
       "13    <|user|>\\n%1<|end|>\\n<|assistant|>\\n%2<|end|>\\n   \n",
       "14                   ### User:\\n%1\\n\\n### Response:\\n   \n",
       "15                                                 %1   \n",
       "16                                                 %1   \n",
       "17                                                 %1   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                               USER: %1 ASSISTANT:    \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "\n",
       "                                         systemPrompt removedIn disableGUI  \\\n",
       "0                                                           NaN        NaN   \n",
       "1                                                           NaN        NaN   \n",
       "2                                                           NaN        NaN   \n",
       "3   <|im_start|>system\\nYou are MistralOrca, a lar...       NaN        NaN   \n",
       "4                                                           NaN        NaN   \n",
       "5                                                           NaN        NaN   \n",
       "6                                                           NaN        NaN   \n",
       "7                                                           NaN        NaN   \n",
       "8   <|system|>\\nYou are Ghost created by Lam Hieu....       NaN        NaN   \n",
       "9                                                           NaN        NaN   \n",
       "10                                                          NaN        NaN   \n",
       "11  <|im_start|>system\\n- You are a helpful assist...     2.7.3        NaN   \n",
       "12  <|im_start|>system\\n- You are a helpful assist...       NaN        NaN   \n",
       "13                                                          NaN        NaN   \n",
       "14  ### System:\\nYou are an AI assistant that foll...       NaN        NaN   \n",
       "15                                                          NaN       true   \n",
       "16                                                          NaN       true   \n",
       "17                                                          NaN       true   \n",
       "18                                                        2.7.4       true   \n",
       "19                                                NaN       NaN        NaN   \n",
       "20                Du bist ein hilfreicher Assistent.        NaN        NaN   \n",
       "21                                                          NaN       true   \n",
       "22                                                          NaN       true   \n",
       "\n",
       "   embeddingModel  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "5             NaN  \n",
       "6             NaN  \n",
       "7             NaN  \n",
       "8             NaN  \n",
       "9             NaN  \n",
       "10            NaN  \n",
       "11            NaN  \n",
       "12            NaN  \n",
       "13            NaN  \n",
       "14            NaN  \n",
       "15            NaN  \n",
       "16            NaN  \n",
       "17            NaN  \n",
       "18           True  \n",
       "19           True  \n",
       "20            NaN  \n",
       "21           True  \n",
       "22           True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
